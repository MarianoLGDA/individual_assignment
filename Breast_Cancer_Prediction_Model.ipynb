{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc03406e",
   "metadata": {},
   "source": [
    "# Breast Cancer Prediction Model\n",
    "This notebook demonstrates loading, preprocessing, training, and saving a Random Forest model to predict breast cancer diagnosis. It also includes code for deploying the model using Streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec76bb8",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "We'll start by importing necessary libraries for data handling, model training, and saving/loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe93a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03736c0",
   "metadata": {},
   "source": [
    "## Step 2: Load and Prepare the Data\n",
    "Load the breast cancer dataset, drop unnecessary columns, encode the target variable, and split into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3267e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = pd.read_csv('breast_cancer.csv').drop(columns=['id'])\n",
    "X = cancer_data.drop(columns=['diagnosis'])\n",
    "y = LabelEncoder().fit_transform(cancer_data['diagnosis'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2a5250",
   "metadata": {},
   "source": [
    "To see the structure of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea40ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f317f9",
   "metadata": {},
   "source": [
    "## Step 3: Standardize the Data\n",
    "Standardize the features to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373fab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b33be",
   "metadata": {},
   "source": [
    "## Step 4: Set Up and Train the Model\n",
    "We switch to using a Random Forest classifier as it often performs better on structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e164183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53094c42",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the Model\n",
    "Use metrics like accuracy, precision, recall, and F1 score to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050b6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)\n",
    "\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec2a699",
   "metadata": {},
   "source": [
    "## Step 6: Save the Model and Scaler\n",
    "Save the trained Random Forest model and scaler so they can be used in the Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf_model, 'rf_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "print('Random Forest model and scaler saved as .pkl files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6c2b94",
   "metadata": {},
   "source": [
    "## Step 7: Create a Streamlit App\n",
    "We now create a Streamlit app to load the model and scaler, allow users to upload new data, and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model_and_scaler():\n",
    "    model = joblib.load('rf_model.pkl')\n",
    "    scaler = joblib.load('scaler.pkl')\n",
    "    return model, scaler\n",
    "\n",
    "# Main app\n",
    "st.title('Breast Cancer Prediction using Random Forest')\n",
    "st.write('Upload your data file in the same format to get predictions.')\n",
    "\n",
    "# Load model and scaler\n",
    "model, scaler = load_model_and_scaler()\n",
    "\n",
    "# File uploader\n",
    "uploaded_file = st.file_uploader('Upload a CSV file', type=['csv'])\n",
    "if uploaded_file is not None:\n",
    "    input_data = pd.read_csv(uploaded_file)\n",
    "    input_data = input_data.drop(columns=['id', 'diagnosis'], errors='ignore')\n",
    "\n",
    "    # Scale the input data\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(input_data_scaled)\n",
    "    predictions = ['Benign' if pred == 0 else 'Malignant' for pred in predictions]\n",
    "\n",
    "    # Display results\n",
    "    st.write('Predictions:')\n",
    "    st.write(predictions)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
